{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sx9jMMwyUqRy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = None\n",
        "        self.fc_input_features = None\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 128)\n",
        "        self.fc5 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.fc_input_features is None:\n",
        "            self.fc_input_features = x.size(1)\n",
        "            self.fc1 = nn.Linear(self.fc_input_features, 1024).to(x.device)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "def train(model, optimizer, train_dataloader, device):\n",
        "    model.train()\n",
        "    for data, target in train_dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(model, test_dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for data in test_dataloader:\n",
        "            data = data[0].to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            predictions.extend(pred.cpu().numpy())\n",
        "    return np.array(predictions).flatten()\n",
        "\n",
        "\n",
        "\n",
        "def learn(X, y, n_epochs=10, batch_size=32, lr=0.001, weight_decay=1e-3):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    X = X.reshape(-1, 1, 28, 84)\n",
        "    y = y.astype(int)\n",
        "\n",
        "    dataset = TensorDataset(torch.Tensor(X), torch.LongTensor(y))\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train(model, optimizer, dataloader, device)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def classify(Xtest, model):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    Xtest = Xtest.reshape(-1, 1, 28, 84)\n",
        "    test_dataset = TensorDataset(torch.Tensor(Xtest))\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    return test(model, test_dataloader, device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(file_name):\n",
        "    train_data = np.loadtxt(file_name, delimiter=',')\n",
        "    y = train_data[:, 0]\n",
        "    X = train_data[:, 1:] / 255.0\n",
        "    X = X.reshape(-1, 1, 28, 84)\n",
        "    tensor_X = torch.Tensor(X)\n",
        "    tensor_y = torch.LongTensor(y)\n",
        "    dataset = TensorDataset(tensor_X, tensor_y)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "    return dataset, dataloader"
      ],
      "metadata": {
        "id": "nx7E-1xGXIJV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    dataset, _ = prepareData('sample_data/A4train.csv')\n",
        "    test_dataset, test_dataloader = prepareData('sample_data/A4val.csv')\n",
        "\n",
        "\n",
        "    X, y = dataset.tensors[0].numpy(), dataset.tensors[1].numpy()\n",
        "    Xtest, ytest = test_dataset.tensors[0].numpy(), test_dataset.tensors[1].numpy()\n",
        "\n",
        "    model = learn(X, y)\n",
        "\n",
        "    # Classify test data\n",
        "    yhat = classify(Xtest, model)\n",
        "    #print(\"Predictions:\", yhat)\n"
      ],
      "metadata": {
        "id": "XMmOd-MYU9oE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "ZMzNAO4TX7KM"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}